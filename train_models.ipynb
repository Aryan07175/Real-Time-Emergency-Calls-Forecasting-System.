{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš¨ Emergency Calls Forecasting - Model Training Notebook\n",
        "\n",
        "This notebook provides a systematic approach to train and save ARIMA and Prophet models for emergency calls forecasting.\n",
        "\n",
        "## Steps:\n",
        "1. **Data Loading & Preprocessing**\n",
        "2. **Data Exploration & Visualization**\n",
        "3. **Train-Test Split**\n",
        "4. **ARIMA Model Training**\n",
        "5. **Prophet Model Training**\n",
        "6. **Model Evaluation**\n",
        "7. **Save Trained Models**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import project modules\n",
        "from data_preprocessing import process_dataset\n",
        "from model_training import (\n",
        "    train_arima, forecast_arima, save_arima_model, load_arima_model,\n",
        "    train_prophet, forecast_prophet, save_prophet_model, load_prophet_model,\n",
        "    evaluate_model, auto_arima_params\n",
        ")\n",
        "\n",
        "print(\"âœ“ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Data Loading & Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess the dataset\n",
        "print(\"Loading and preprocessing data...\")\n",
        "hourly_df, processed_df, location_df = process_dataset('911.csv')\n",
        "\n",
        "if hourly_df is not None:\n",
        "    print(f\"\\nâœ“ Data loaded successfully!\")\n",
        "    print(f\"  Total hourly records: {len(hourly_df)}\")\n",
        "    print(f\"  Date range: {hourly_df['timeStamp'].min()} to {hourly_df['timeStamp'].max()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(hourly_df.head())\n",
        "    print(f\"\\nDataset info:\")\n",
        "    print(hourly_df.info())\n",
        "else:\n",
        "    print(\"âœ— Failed to load data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Data Exploration & Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "print(\"=\" * 60)\n",
        "print(\"DATA STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total calls: {hourly_df['call_count'].sum():,}\")\n",
        "print(f\"Average calls per hour: {hourly_df['call_count'].mean():.2f}\")\n",
        "print(f\"Median calls per hour: {hourly_df['call_count'].median():.2f}\")\n",
        "print(f\"Std deviation: {hourly_df['call_count'].std():.2f}\")\n",
        "print(f\"Min calls per hour: {hourly_df['call_count'].min()}\")\n",
        "print(f\"Max calls per hour: {hourly_df['call_count'].max()}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot time series\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=hourly_df['timeStamp'],\n",
        "    y=hourly_df['call_count'],\n",
        "    mode='lines',\n",
        "    name='Hourly Call Count',\n",
        "    line=dict(color='#FF4444', width=1)\n",
        "))\n",
        "fig.update_layout(\n",
        "    title='Emergency Calls Over Time',\n",
        "    xaxis_title='Timestamp',\n",
        "    yaxis_title='Number of Calls',\n",
        "    hovermode='x unified',\n",
        "    height=500\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hourly pattern\n",
        "hourly_pattern = hourly_df.groupby('hour')['call_count'].mean().reset_index()\n",
        "fig = px.bar(\n",
        "    hourly_pattern,\n",
        "    x='hour',\n",
        "    y='call_count',\n",
        "    title='Average Calls by Hour of Day',\n",
        "    labels={'hour': 'Hour of Day', 'call_count': 'Average Calls'},\n",
        "    color='call_count',\n",
        "    color_continuous_scale='Reds'\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day of week pattern\n",
        "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "daily_pattern = hourly_df.groupby('day_of_week')['call_count'].mean().reset_index()\n",
        "daily_pattern['day_name'] = daily_pattern['day_of_week'].map(lambda x: day_names[x])\n",
        "\n",
        "fig = px.bar(\n",
        "    daily_pattern,\n",
        "    x='day_name',\n",
        "    y='call_count',\n",
        "    title='Average Calls by Day of Week',\n",
        "    labels={'day_name': 'Day of Week', 'call_count': 'Average Calls'},\n",
        "    color='call_count',\n",
        "    color_continuous_scale='Oranges'\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Train-Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train and test sets (80-20 split)\n",
        "split_idx = int(len(hourly_df) * 0.8)\n",
        "train_df = hourly_df.iloc[:split_idx].copy()\n",
        "test_df = hourly_df.iloc[split_idx:].copy()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAIN-TEST SPLIT\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training set: {len(train_df)} records ({len(train_df)/len(hourly_df)*100:.1f}%)\")\n",
        "print(f\"  Date range: {train_df['timeStamp'].min()} to {train_df['timeStamp'].max()}\")\n",
        "print(f\"Test set: {len(test_df)} records ({len(test_df)/len(hourly_df)*100:.1f}%)\")\n",
        "print(f\"  Date range: {test_df['timeStamp'].min()} to {test_df['timeStamp'].max()}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: ARIMA Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Auto-tune ARIMA parameters (slower but more accurate)\n",
        "# Uncomment the following lines to use auto-tuning\n",
        "# print(\"Auto-tuning ARIMA parameters...\")\n",
        "# ts_train = train_df.set_index('timeStamp')['call_count']\n",
        "# best_order = auto_arima_params(ts_train, max_p=3, max_d=2, max_q=3)\n",
        "# arima_order = best_order\n",
        "\n",
        "# Option 2: Use predefined order (faster)\n",
        "arima_order = (2, 1, 2)\n",
        "print(f\"Using ARIMA order: {arima_order}\")\n",
        "\n",
        "# Train ARIMA model\n",
        "print(\"\\nTraining ARIMA model...\")\n",
        "arima_model = train_arima(train_df, auto_tune=False, order=arima_order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display ARIMA model summary\n",
        "if arima_model is not None:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ARIMA MODEL SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(arima_model.summary())\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate forecast on test set for evaluation\n",
        "if arima_model is not None:\n",
        "    test_steps = len(test_df)\n",
        "    arima_forecast = forecast_arima(arima_model, steps=test_steps)\n",
        "    \n",
        "    print(f\"\\nARIMA Forecast generated for {test_steps} hours\")\n",
        "    display(arima_forecast.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize ARIMA forecast vs actual\n",
        "if arima_model is not None and arima_forecast is not None:\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # Historical training data (last 168 hours = 1 week)\n",
        "    hist_df = train_df.tail(168)\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=hist_df['timeStamp'],\n",
        "        y=hist_df['call_count'],\n",
        "        mode='lines',\n",
        "        name='Training Data (last week)',\n",
        "        line=dict(color='blue', width=2)\n",
        "    ))\n",
        "    \n",
        "    # Actual test data\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=test_df['timeStamp'],\n",
        "        y=test_df['call_count'],\n",
        "        mode='lines',\n",
        "        name='Actual (Test)',\n",
        "        line=dict(color='green', width=2)\n",
        "    ))\n",
        "    \n",
        "    # Forecast\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=arima_forecast['timeStamp'],\n",
        "        y=arima_forecast['forecast'],\n",
        "        mode='lines',\n",
        "        name='ARIMA Forecast',\n",
        "        line=dict(color='red', width=2, dash='dash')\n",
        "    ))\n",
        "    \n",
        "    # Confidence intervals\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=arima_forecast['timeStamp'],\n",
        "        y=arima_forecast['upper_bound'],\n",
        "        mode='lines',\n",
        "        name='Upper Bound',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ))\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=arima_forecast['timeStamp'],\n",
        "        y=arima_forecast['lower_bound'],\n",
        "        mode='lines',\n",
        "        name='Confidence Interval',\n",
        "        fill='tonexty',\n",
        "        fillcolor='rgba(255,0,0,0.2)',\n",
        "        line=dict(width=0)\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='ARIMA Model: Forecast vs Actual',\n",
        "        xaxis_title='Timestamp',\n",
        "        yaxis_title='Number of Calls',\n",
        "        hovermode='x unified',\n",
        "        height=600\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Prophet Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Prophet model\n",
        "print(\"Training Prophet model...\")\n",
        "prophet_model = train_prophet(train_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate forecast on test set\n",
        "if prophet_model is not None:\n",
        "    test_periods = len(test_df)\n",
        "    prophet_forecast = forecast_prophet(prophet_model, periods=test_periods)\n",
        "    \n",
        "    print(f\"\\nProphet Forecast generated for {test_periods} hours\")\n",
        "    display(prophet_forecast.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Prophet forecast vs actual\n",
        "if prophet_model is not None and prophet_forecast is not None:\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # Historical training data (last 168 hours = 1 week)\n",
        "    hist_df = train_df.tail(168)\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=hist_df['timeStamp'],\n",
        "        y=hist_df['call_count'],\n",
        "        mode='lines',\n",
        "        name='Training Data (last week)',\n",
        "        line=dict(color='blue', width=2)\n",
        "    ))\n",
        "    \n",
        "    # Actual test data\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=test_df['timeStamp'],\n",
        "        y=test_df['call_count'],\n",
        "        mode='lines',\n",
        "        name='Actual (Test)',\n",
        "        line=dict(color='green', width=2)\n",
        "    ))\n",
        "    \n",
        "    # Forecast\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=prophet_forecast['timeStamp'],\n",
        "        y=prophet_forecast['forecast'],\n",
        "        mode='lines',\n",
        "        name='Prophet Forecast',\n",
        "        line=dict(color='purple', width=2, dash='dash')\n",
        "    ))\n",
        "    \n",
        "    # Confidence intervals\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=prophet_forecast['timeStamp'],\n",
        "        y=prophet_forecast['upper_bound'],\n",
        "        mode='lines',\n",
        "        name='Upper Bound',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ))\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=prophet_forecast['timeStamp'],\n",
        "        y=prophet_forecast['lower_bound'],\n",
        "        mode='lines',\n",
        "        name='Confidence Interval',\n",
        "        fill='tonexty',\n",
        "        fillcolor='rgba(128,0,128,0.2)',\n",
        "        line=dict(width=0)\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='Prophet Model: Forecast vs Actual',\n",
        "        xaxis_title='Timestamp',\n",
        "        yaxis_title='Number of Calls',\n",
        "        hovermode='x unified',\n",
        "        height=600\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate ARIMA model\n",
        "if arima_model is not None and arima_forecast is not None:\n",
        "    # Align test data with forecast\n",
        "    test_ts = test_df.set_index('timeStamp')['call_count']\n",
        "    forecast_ts = arima_forecast.set_index('timeStamp')['forecast']\n",
        "    \n",
        "    # Get common indices\n",
        "    common_idx = test_ts.index.intersection(forecast_ts.index)\n",
        "    if len(common_idx) > 0:\n",
        "        test_aligned = test_ts.loc[common_idx]\n",
        "        forecast_aligned = forecast_ts.loc[common_idx]\n",
        "        \n",
        "        # Calculate metrics\n",
        "        mae_arima = np.mean(np.abs(test_aligned - forecast_aligned))\n",
        "        mse_arima = np.mean((test_aligned - forecast_aligned) ** 2)\n",
        "        rmse_arima = np.sqrt(mse_arima)\n",
        "        mape_arima = np.mean(np.abs((test_aligned - forecast_aligned) / test_aligned)) * 100\n",
        "        \n",
        "        arima_metrics = {\n",
        "            'MAE': mae_arima,\n",
        "            'MSE': mse_arima,\n",
        "            'RMSE': rmse_arima,\n",
        "            'MAPE': mape_arima\n",
        "        }\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        print(\"ARIMA MODEL EVALUATION METRICS\")\n",
        "        print(\"=\" * 60)\n",
        "        for metric, value in arima_metrics.items():\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "        print(\"=\" * 60)\n",
        "    else:\n",
        "        arima_metrics = None\n",
        "        print(\"âœ— Could not align test data with forecast\")\n",
        "else:\n",
        "    arima_metrics = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Prophet model\n",
        "if prophet_model is not None and prophet_forecast is not None:\n",
        "    # Align test data with forecast\n",
        "    test_ts = test_df.set_index('timeStamp')['call_count']\n",
        "    forecast_ts = prophet_forecast.set_index('timeStamp')['forecast']\n",
        "    \n",
        "    # Get common indices\n",
        "    common_idx = test_ts.index.intersection(forecast_ts.index)\n",
        "    if len(common_idx) > 0:\n",
        "        test_aligned = test_ts.loc[common_idx]\n",
        "        forecast_aligned = forecast_ts.loc[common_idx]\n",
        "        \n",
        "        # Calculate metrics\n",
        "        mae_prophet = np.mean(np.abs(test_aligned - forecast_aligned))\n",
        "        mse_prophet = np.mean((test_aligned - forecast_aligned) ** 2)\n",
        "        rmse_prophet = np.sqrt(mse_prophet)\n",
        "        mape_prophet = np.mean(np.abs((test_aligned - forecast_aligned) / test_aligned)) * 100\n",
        "        \n",
        "        prophet_metrics = {\n",
        "            'MAE': mae_prophet,\n",
        "            'MSE': mse_prophet,\n",
        "            'RMSE': rmse_prophet,\n",
        "            'MAPE': mape_prophet\n",
        "        }\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        print(\"PROPHET MODEL EVALUATION METRICS\")\n",
        "        print(\"=\" * 60)\n",
        "        for metric, value in prophet_metrics.items():\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "        print(\"=\" * 60)\n",
        "    else:\n",
        "        prophet_metrics = None\n",
        "        print(\"âœ— Could not align test data with forecast\")\n",
        "else:\n",
        "    prophet_metrics = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare both models\n",
        "if arima_metrics is not None and prophet_metrics is not None:\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'ARIMA': arima_metrics,\n",
        "        'Prophet': prophet_metrics\n",
        "    })\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"MODEL COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "    display(comparison_df)\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Visualize comparison\n",
        "    fig = go.Figure()\n",
        "    metrics = ['MAE', 'RMSE', 'MAPE']\n",
        "    fig.add_trace(go.Bar(name='ARIMA', x=metrics, y=[arima_metrics[m] for m in metrics]))\n",
        "    fig.add_trace(go.Bar(name='Prophet', x=metrics, y=[prophet_metrics[m] for m in metrics]))\n",
        "    fig.update_layout(\n",
        "        title='Model Comparison: Lower is Better',\n",
        "        yaxis_title='Metric Value',\n",
        "        barmode='group',\n",
        "        height=400\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Save Trained Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs('models', exist_ok=True)\n",
        "print(\"âœ“ Models directory ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save ARIMA model\n",
        "if arima_model is not None:\n",
        "    arima_saved = save_arima_model(arima_model, filepath='models/arima_model.pkl')\n",
        "    if arima_saved:\n",
        "        print(\"âœ“ ARIMA model saved successfully!\")\n",
        "    else:\n",
        "        print(\"âœ— Failed to save ARIMA model\")\n",
        "else:\n",
        "    print(\"âœ— No ARIMA model to save\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Prophet model\n",
        "if prophet_model is not None:\n",
        "    prophet_saved = save_prophet_model(prophet_model, filepath='models/prophet_model.pkl')\n",
        "    if prophet_saved:\n",
        "        print(\"âœ“ Prophet model saved successfully!\")\n",
        "    else:\n",
        "        print(\"âœ— Failed to save Prophet model\")\n",
        "else:\n",
        "    print(\"âœ— No Prophet model to save\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify saved models can be loaded\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"VERIFYING SAVED MODELS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test loading ARIMA\n",
        "if arima_model is not None:\n",
        "    loaded_arima = load_arima_model('models/arima_model.pkl')\n",
        "    if loaded_arima is not None:\n",
        "        print(\"âœ“ ARIMA model can be loaded successfully\")\n",
        "    else:\n",
        "        print(\"âœ— Failed to load ARIMA model\")\n",
        "\n",
        "# Test loading Prophet\n",
        "if prophet_model is not None:\n",
        "    loaded_prophet = load_prophet_model('models/prophet_model.pkl')\n",
        "    if loaded_prophet is not None:\n",
        "        print(\"âœ“ Prophet model can be loaded successfully\")\n",
        "    else:\n",
        "        print(\"âœ— Failed to load Prophet model\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Generate Future Forecasts (24 hours ahead)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate 24-hour ahead forecast using ARIMA\n",
        "if arima_model is not None:\n",
        "    future_arima = forecast_arima(arima_model, steps=24)\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ARIMA 24-HOUR AHEAD FORECAST\")\n",
        "    print(\"=\" * 60)\n",
        "    display(future_arima)\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate 24-hour ahead forecast using Prophet\n",
        "if prophet_model is not None:\n",
        "    future_prophet = forecast_prophet(prophet_model, periods=24)\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PROPHET 24-HOUR AHEAD FORECAST\")\n",
        "    print(\"=\" * 60)\n",
        "    display(future_prophet)\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize both 24-hour forecasts\n",
        "if arima_model is not None and prophet_model is not None:\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # Last week of training data\n",
        "    hist_df = train_df.tail(168)\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=hist_df['timeStamp'],\n",
        "        y=hist_df['call_count'],\n",
        "        mode='lines',\n",
        "        name='Historical Data (last week)',\n",
        "        line=dict(color='blue', width=2)\n",
        "    ))\n",
        "    \n",
        "    # ARIMA forecast\n",
        "    if future_arima is not None:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=future_arima['timeStamp'],\n",
        "            y=future_arima['forecast'],\n",
        "            mode='lines',\n",
        "            name='ARIMA Forecast (24h)',\n",
        "            line=dict(color='red', width=2, dash='dash')\n",
        "        ))\n",
        "        # ARIMA confidence interval\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=future_arima['timeStamp'],\n",
        "            y=future_arima['upper_bound'],\n",
        "            mode='lines',\n",
        "            name='ARIMA Upper',\n",
        "            line=dict(width=0),\n",
        "            showlegend=False\n",
        "        ))\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=future_arima['timeStamp'],\n",
        "            y=future_arima['lower_bound'],\n",
        "            mode='lines',\n",
        "            name='ARIMA CI',\n",
        "            fill='tonexty',\n",
        "            fillcolor='rgba(255,0,0,0.1)',\n",
        "            line=dict(width=0)\n",
        "        ))\n",
        "    \n",
        "    # Prophet forecast\n",
        "    if future_prophet is not None:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=future_prophet['timeStamp'],\n",
        "            y=future_prophet['forecast'],\n",
        "            mode='lines',\n",
        "            name='Prophet Forecast (24h)',\n",
        "            line=dict(color='purple', width=2, dash='dot')\n",
        "        ))\n",
        "        # Prophet confidence interval\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=future_prophet['timeStamp'],\n",
        "            y=future_prophet['upper_bound'],\n",
        "            mode='lines',\n",
        "            name='Prophet Upper',\n",
        "            line=dict(width=0),\n",
        "            showlegend=False\n",
        "        ))\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=future_prophet['timeStamp'],\n",
        "            y=future_prophet['lower_bound'],\n",
        "            mode='lines',\n",
        "            name='Prophet CI',\n",
        "            fill='tonexty',\n",
        "            fillcolor='rgba(128,0,128,0.1)',\n",
        "            line=dict(width=0)\n",
        "        ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='24-Hour Ahead Forecasts: ARIMA vs Prophet',\n",
        "        xaxis_title='Timestamp',\n",
        "        yaxis_title='Number of Calls',\n",
        "        hovermode='x unified',\n",
        "        height=600\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Training Complete!\n",
        "\n",
        "Both models have been trained, evaluated, and saved successfully. The models are now ready to be used in the Streamlit dashboard or for production forecasting.\n",
        "\n",
        "### Summary:\n",
        "- âœ… ARIMA model trained and saved to `models/arima_model.pkl`\n",
        "- âœ… Prophet model trained and saved to `models/prophet_model.pkl`\n",
        "- âœ… Models evaluated on test set\n",
        "- âœ… 24-hour ahead forecasts generated\n",
        "\n",
        "### Next Steps:\n",
        "1. Use the saved models in the Streamlit dashboard\n",
        "2. Load models using `load_arima_model()` and `load_prophet_model()`\n",
        "3. Generate forecasts for real-time predictions\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
